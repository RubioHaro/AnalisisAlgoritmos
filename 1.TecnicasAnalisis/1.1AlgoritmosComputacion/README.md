Algoritmo es un conjunto ordenado y finito de operaciones que permiten encontrar la solución a un problema.

Los primeros algoritmos registrados datan de Babilonia, originados en las matematicas como un método para resolver un problema usando una secuencia de cálculos más simples. Esta palabra tiene su origen en el nombre de un famoso matemático y erudito árabe del siglo IX, Mahommed ibn Musa Al-Khwarizmi (nacido en la actual Uzbekistán en el año 780 - fallecio alrededor del año 835). En su libro De numero indiorum (Tratado sobre los numeros indios) describió reglas para hacer operaciones aritméticas. Estas reglas se denominaron como las reglas de Al-Khwarizmi y por deformación de la palabra llego al término actual algoritmo.

Su trabajo con los algoritmos introdujo el método de cálculo con la utilización de la numeración arábiga y la notación decimal; preservó y difundio el conocimiento de los griegos e indios; rescatando de los griegos su rigurosidad y de los indios su simplicidad. Las matemáticas le deben a al-Khwarizmi la introducción del sistema de numeración actual y el álgebra. Su obra Kitab al-jabr wa al-muqabalah fue traducida al latín en el siglo XII dando origen a la palabra álbebra. En ella se compilan una seria de reglas con el fin de obtener las soluciones aritmeticas de las ecuaciones lineales y de las cuadráticas; 

Un algoritmo se usa para denominar a la secuencia de pasos a seguir para resolver un problema usando una computadora. Por esta razón, la algoritmia o ciencia de los algoritmos, es uno de los pilares de la computación.

El análisis de algoritmos es una parte importante de la Teoría de complejidad computacional, que provee estimaciones teóricas para los recursos que necesita cualquier algoritmo que resuelva un problema computacional dado. Estas estimaciones resultan ser bastante útiles en la búsqueda de algoritmos eficientes.

Los temas de mayor interés son el analisis teórico de algoritmos lo que permite calcular su complejidad en unsentido asintótico, así como el análisis de problemas comunes que requieran una cantidad de procesamiento alta de los datos para poder ser resueltos con exactitud o aproximación a la respuesta óptima.

Es un error creer que los algoritmos son exclusivos de la computación, el algoritmo más famoso de la historia es el algoritmo de Euclides para calcular el máximo común divisor.

Para los años 30's y 40's se dió la investigación de los modelos formales de computación de la mano de Alan Turing, emil Leon Post, Alonzo Church, por mencionar algunos. Para los años 50's y 60's los lenguajes de programación, compiladores y sistemas operativos estaban en desarrollo, por lo tanto, se convirtieron tanto en el sujeto como la base para la mayoría del trabajo teórico.

El poder de las computadoras en este período estaba limitado por procesadores lentos y por pequeñas cantidades de memoria. Así, se desarrollaron teorías (modelos, algoritmos y análisis) para hacer un uso eficiente de las, ademas, costosas computadoras. Esto daría origen al desarrollo del área que ahora se conoce como "Algoritmos y Estructuras de Datos". 

Al mismo tiempo se hicieton estudios para comprender la complejidad inherente en la solución de algunos problemas. Esto dió origen a lo que se conoce como la "Jerarquía de problemas computacionales" y al área de "Complejidad Computacional".

Algoritmo

    "Un algoritmo es una serie finita de pasos para resolver un problema"

    Para que un algoritmo exista: 
        1. El número de pasos debe ser finito. de esta manera el algoritmo debe terminar en un timepo finito con la solución del problema.

        2. El algoritmo debe de ser capaz de determinar la solución del problema.

    De este modo, podemos definir algoritmo computacional como un 
    "Conjunto de reglas operacionales inherentes a un computo"

    Se trata de un método sistemático, susceptible de ser realizado mecánicamente, para resolver un problema dado en un tiempo finito.

    Características de un Algoritmo
    1. Entrada: Definir lo que necesita el algoritmo
    2. Salida: Definir lo que produce
    3. Sin ambiguedad: explícito, siempre sabe qué comando ejecutar
    4. Finito: el algoritmo termina en un número finito de pasos.
    5. Correcto: La solución debe ser correcta
    6. Efectividad: Cada instrucción se completa en tiempo finito.
    7. General: debe contemplar todos los casos de entrada.

    Una definición formal para el algoritmo es:

    "Un algoritmo es un procedimiento para resolver un problema cuyos pasos son concretos y no ambiguos. El algoritmo debe ser correcto, de longitud finita y debe terminar para todas las entradas"

    Un algoritmo puede ser visto como una funci+on que depende de una entrada y asocia una salida, matemáticamente se expresa de la siguiente forma: 

    y = f(x)

    donde: 
    "y" es la salida
    "x" es la entrada
    "f(x)" es el algoritmo que depende de la entrada

    Importancia de los algoritmos en la Computación

    Evitan Reinventar Soluciones. 
    A no ser que se este investigando aún más lo solución de un problema es conveniente usar un algoritmo conocido. Para muchos problemas existen buenos algoritmos, de los que ya se han hecho analisis de confianza, eficiencia, velocidad, etc.

    Introducción a la Complejidad de los algoritmos
    En Ciencias de la Computación cuando se dice que un problema tiene solución, significa que existe un algoritmo susceptible de implantarse en una computadora, capaz de producir la respuesta correcta para cualquier instancia (o caso) del problema en cuestión.
    
    Para ciertos problemas es posible encontrar más de un algoritmo capaz de resolverlos. Por lo que ahora, la tarea es dicidir cuál de ellos es el mejor. Esto se define deacuerdo a nuestros intereses. En la mayoría de los casos la elección de un buen algoritmo está orientada hacia la disminución del costo que implica la solución del problema.

    Costo:
    El costo que implica resolver un problema genera dos criterios para la selección del algoritmo:

    1. Criterios para minimizar el costo de desarrollo: claridad, sencillez, facilidad de implementación, depuración y mantenimiento. (si se usa poco)
    2. Criterios para disminuir el costo de ejecución: tiempo de procesador y cantidad de memoria utilizados. (si se usa mucho)

    Los recursos que consume un algoritmo pueden estimarse mediante herramientas teóricas y constituyen, por lo tanto, una base confiable para la elección de un algoritmo.

    Un algoritmo es eficaz cuando alcanza el objetivo primordial, el analisis de resolución del problema se realiza prioritariamente.

    Un algoritmo es eficiente cuando logra llegar a sus objetivos planteados utilizando la menor cantidad de recursos posibles.

    Por tanto, puede existir el caso que un algoritmo sea eficaz pero no eficiente.

    La eficiencia de un programa tiene dos ingredientes fundamentales: espacio y tiempo. ambas dependen del tipo de equipo de computo, compilador, sistema operativo, etc. por lo que no se estudiará aquí la eficiencia de los programas, sino la eficiencia de los algoritmos.